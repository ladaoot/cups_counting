from __future__ import annotations

import json
import tempfile
from pathlib import Path
from typing import Dict, List

import numpy as np
import pandas as pd
import streamlit as st
from PIL import Image

from src.history import HistoryRecord, append_history, clear_history, read_history, utc_now_iso
from src.infer import detect_and_count_on_image, detect_and_count_on_video, load_model
from src.reports import make_excel_bytes, make_pdf_bytes


APP_TITLE = "–ü—Ä–∞–∫—Ç–∏–∫–∞ CV: –ø–æ–¥—Å—á—ë—Ç —Å—Ç–∞–∫–∞–Ω–æ–≤/–∫—Ä—É–∂–µ–∫ (YOLOv8)"
DATA_DIR = Path("data")
HISTORY_PATH = DATA_DIR / "history.jsonl"


def _parse_target_classes(text: str) -> List[str]:
    # Accept comma/space separated
    raw = [t.strip() for t in text.replace(";", ",").split(",")]
    return [t for t in raw if t]


def _save_uploaded_to_temp(uploaded) -> str:
    suffix = Path(uploaded.name).suffix or ""
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as f:
        f.write(uploaded.getbuffer())
        return f.name


def _get_class_ids(model, class_names: List[str]) -> List[int]:
    names = getattr(model, "names", {}) or {}
    want = {c.strip().lower() for c in class_names if c.strip()}
    out: List[int] = []
    for cid, cname in names.items():
        if str(cname).lower() in want:
            out.append(int(cid))
    return out


st.set_page_config(page_title=APP_TITLE, layout="wide")
st.title(APP_TITLE)

with st.sidebar:
    st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏")
    model_path = st.text_input("–ú–æ–¥–µ–ª—å (–≤–µ—Å–∞ Ultralytics)", value="yolov8n.pt", help="–ù–∞–ø—Ä–∏–º–µ—Ä: yolov8n.pt / yolov8s.pt")
    st.info("üîç –ü–æ–∏—Å–∫: —Å—Ç–∞–∫–∞–Ω—ã –∏ –∫—Ä—É–∂–∫–∏ (cup)")
    conf = st.slider("Confidence", 0.05, 0.95, 0.35, 0.05)
    iou = st.slider("IoU", 0.05, 0.95, 0.45, 0.05)

    st.subheader("–í–∏–¥–µ–æ")
    sample_every = st.number_input("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∫–∞–∂–¥—ã–π N‚Äë–π –∫–∞–¥—Ä", min_value=1, max_value=30, value=1, step=1)
    
    st.subheader("–ö–∞–º–µ—Ä–∞")
    auto_save_enabled = st.checkbox("–ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ", value=True)
    auto_save_interval = st.number_input("–ò–Ω—Ç–µ—Ä–≤–∞–ª –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (—Å–µ–∫)", min_value=5, max_value=300, value=15, step=5, disabled=not auto_save_enabled)

tabs = st.tabs(["–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "–í–∏–¥–µ–æ", "–ö–∞–º–µ—Ä–∞", "–ò—Å—Ç–æ—Ä–∏—è –∏ –æ—Ç—á—ë—Ç—ã"])


with tabs[0]:
    st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–Ω–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –Ω–∞–∂–º–∏—Ç–µ **–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É**.")
    up_list = st.file_uploader(
        "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (jpg/png/webp)", 
        type=["jpg", "jpeg", "png", "webp"],
        accept_multiple_files=True
    )
    run = st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", type="primary", disabled=not up_list)

    if up_list:
        st.write(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: **{len(up_list)}**")
        cols = st.columns(min(3, len(up_list)))
        for idx, up in enumerate(up_list):
            with cols[idx % len(cols)]:
                img = Image.open(up).convert("RGB")
                st.image(img, caption=up.name, use_container_width=True)

    if run and up_list:
        classes = ["cup"]  # –í—Å–µ–≥–¥–∞ –∏—â–µ–º —Å—Ç–∞–∫–∞–Ω—ã/–∫—Ä—É–∂–∫–∏
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for idx, up in enumerate(up_list):
            status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {idx + 1}/{len(up_list)}: {up.name}")
            progress_bar.progress((idx + 1) / len(up_list))
            
            image_rgb = np.array(Image.open(up).convert("RGB"))
            annotated_rgb, summary = detect_and_count_on_image(
                image_rgb,
                model_path=model_path,
                target_classes=classes,
                conf=float(conf),
                iou=float(iou),
            )

            st.subheader(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {up.name}")
            col1, col2 = st.columns([2, 1])
            with col1:
                st.image(annotated_rgb, caption="–ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_container_width=True)
            with col2:
                st.metric("–í—Å–µ–≥–æ –æ–±—ä–µ–∫—Ç–æ–≤", summary.total_count)
                st.metric("–í—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (ms)", f"{summary.inference_ms:.1f}")
                st.metric("–ö–ª–∞—Å—Å—ã", ", ".join(summary.selected_class_names))
                st.json(summary.per_class_count)

            append_history(
                HistoryRecord(
                    ts_iso=utc_now_iso(),
                    kind="image",
                    input_name=up.name,
                    model_name=summary.model_name,
                    target_classes=classes,
                    conf=summary.conf_threshold,
                    iou=summary.iou_threshold,
                    total_count=summary.total_count,
                    per_class_count=summary.per_class_count,
                    inference_ms=summary.inference_ms,
                    image_width=summary.image_width,
                    image_height=summary.image_height,
                ),
                HISTORY_PATH,
            )
        
        progress_bar.empty()
        status_text.empty()
        st.success(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(up_list)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ó–∞–ø–∏—Å–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ –∏—Å—Ç–æ—Ä–∏—é.")


with tabs[1]:
    st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–Ω–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∏–¥–µ–æ –∏ –Ω–∞–∂–º–∏—Ç–µ **–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É** (—Å–æ–∑–¥–∞—Å—Ç—Å—è –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π mp4).")
    upv_list = st.file_uploader(
        "–í–∏–¥–µ–æ (mp4/avi/mov)", 
        type=["mp4", "avi", "mov"],
        accept_multiple_files=True
    )
    runv = st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∏–¥–µ–æ", type="primary", disabled=not upv_list)

    if upv_list:
        st.write(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤–∏–¥–µ–æ: **{len(upv_list)}**")
        for upv in upv_list:
            st.text(f"üìπ {upv.name} ({upv.size / 1024 / 1024:.2f} MB)")

    if runv and upv_list:
        classes = ["cup"]  # –í—Å–µ–≥–¥–∞ –∏—â–µ–º —Å—Ç–∞–∫–∞–Ω—ã/–∫—Ä—É–∂–∫–∏
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for idx, upv in enumerate(upv_list):
            status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ {idx + 1}/{len(upv_list)}: {upv.name}... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è.")
            progress_bar.progress((idx + 1) / len(upv_list))
            
            tmp_in = _save_uploaded_to_temp(upv)
            
            # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è —ç—Ç–æ–≥–æ –≤–∏–¥–µ–æ
            video_progress = st.progress(0)
            video_status = st.empty()
            
            def update_video_progress(p: float):
                video_progress.progress(p)
                video_status.text(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤: {p*100:.1f}%")
            
            with st.spinner(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {upv.name}..."):
                result = detect_and_count_on_video(
                    tmp_in,
                    model_path=model_path,
                    target_classes=classes,
                    conf=float(conf),
                    iou=float(iou),
                    sample_every_n_frames=int(sample_every),
                    progress_callback=update_video_progress,
                )
                # –§—É–Ω–∫—Ü–∏—è –≤—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 3 –∑–Ω–∞—á–µ–Ω–∏—è: out_path, summary, frames_data_path
                out_path, summary, frames_data_path = result
            
            video_progress.empty()
            video_status.empty()

            st.subheader(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {upv.name}")
            st.write(
                f"–ü–æ–¥—Å—á—ë—Ç: **{summary.total_count}** (—Å—Ä–µ–¥–Ω–µ–µ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∫–∞–¥—Ä), "
                f"–º–∞–∫—Å–∏–º—É–º –Ω–∞ –∫–∞–¥—Ä: **{summary.max_per_frame}**"
            )
            st.write(f"–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (ms): **{summary.inference_ms:.1f}**")

            # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–∏–¥–µ–æ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å
            video_file = Path(out_path)
            if video_file.exists():
                with open(video_file, "rb") as video_file_handler:
                    video_bytes = video_file_handler.read()
                    st.video(video_bytes)
                    st.download_button(
                        f"–°–∫–∞—á–∞—Ç—å –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ: {video_file.name}", 
                        data=video_bytes, 
                        file_name=video_file.name,
                        key=f"download_{idx}"
                    )
            else:
                st.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {out_path}")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º –ø–æ –∫–∞–¥—Ä–∞–º –≤ –∏—Å—Ç–æ—Ä–∏–∏
            video_record = HistoryRecord(
                ts_iso=utc_now_iso(),
                kind="video",
                input_name=upv.name,
                model_name=summary.model_name,
                target_classes=classes,
                conf=summary.conf_threshold,
                iou=summary.iou_threshold,
                total_count=summary.total_count,
                per_class_count=summary.per_class_count,
                inference_ms=summary.inference_ms,
                image_width=summary.image_width,
                image_height=summary.image_height,
                output_artifact=str(out_path),
                max_per_frame=summary.max_per_frame,
            )
            append_history(video_record, HISTORY_PATH)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º –ø–æ –∫–∞–¥—Ä–∞–º –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ñ–∞–π–ª–µ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
            if frames_data_path:
                try:
                    frames_index_path = DATA_DIR / "video_frames_index.jsonl"
                    frames_index_path.parent.mkdir(parents=True, exist_ok=True)
                    with frames_index_path.open("a", encoding="utf-8") as f:
                        import json
                        index_entry = {
                            "video_name": upv.name,
                            "frames_data_path": frames_data_path,
                            "ts_iso": video_record.ts_iso
                        }
                        f.write(json.dumps(index_entry, ensure_ascii=False) + "\n")
                except Exception as e:
                    st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–Ω–¥–µ–∫—Å –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–∞–¥—Ä–∞–º: {e}")
        
        progress_bar.empty()
        status_text.empty()
        st.success(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(upv_list)} –≤–∏–¥–µ–æ. –ó–∞–ø–∏—Å–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ –∏—Å—Ç–æ—Ä–∏—é.")


with tabs[2]:
    st.write("–ù–∞–∂–º–∏—Ç–µ **Start**, —á—Ç–æ–±—ã –æ—Ç–∫—Ä—ã—Ç—å –ø–æ—Ç–æ–∫. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–¥—ë—Ç –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ (–º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–¥–ª–µ–Ω–Ω–æ –Ω–∞ CPU).")

    from threading import Lock
    import time
    from datetime import datetime, timezone

    import av  # type: ignore
    from streamlit_webrtc import VideoTransformerBase, webrtc_streamer  # type: ignore

    classes = ["cup"]  # –í—Å–µ–≥–¥–∞ –∏—â–µ–º —Å—Ç–∞–∫–∞–Ω—ã/–∫—Ä—É–∂–∫–∏
    model = load_model(model_path)
    class_ids = _get_class_ids(model, classes)
    stats_lock = Lock()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –∫–∞–º–µ—Ä—ã
    if "camera_last" not in st.session_state:
        st.session_state.camera_last = {"count": 0, "ms": 0.0, "per_class": {}}
    if "camera_last_save" not in st.session_state:
        st.session_state.camera_last_save = 0.0
    if "camera_save_count" not in st.session_state:
        st.session_state.camera_save_count = 0

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â–∏–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –º–µ–∂–¥—É –ø–æ—Ç–æ–∫–∞–º–∏
    camera_shared_state = {"last_save": 0.0, "save_count": 0, "last_count": 0, "last_ms": 0.0, "last_per_class": {}}
    
    class YoloVideoTransformer(VideoTransformerBase):
        def __init__(self):
            self.last_save_time = 0.0
        
        def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
            img = frame.to_ndarray(format="bgr24")
            t0 = time.perf_counter()
            results = model.predict(
                source=img,
                conf=float(conf),
                iou=float(iou),
                classes=class_ids if class_ids else None,
                verbose=False,
                max_det=300,
            )
            r0 = results[0]
            boxes = r0.boxes
            
            # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ–¥—Å—á—ë—Ç: —Å—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã (cup)
            names = getattr(model, "names", {})
            per_class_count: Dict[str, int] = {}
            cnt = 0
            
            if boxes is not None and len(boxes) > 0:
                cls_ids = boxes.cls.detach().cpu().numpy().astype(int)
                for cid in cls_ids:
                    cname = names.get(int(cid), str(int(cid)))
                    # –°—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å
                    if class_ids and int(cid) in class_ids:
                        per_class_count[cname] = per_class_count.get(cname, 0) + 1
                        cnt += 1
            
            dt_ms = (time.perf_counter() - t0) * 1000.0

            plotted = r0.plot()
            current_time = time.time()
            
            with stats_lock:
                # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ)
                camera_shared_state["last_count"] = cnt
                camera_shared_state["last_ms"] = float(dt_ms)
                camera_shared_state["last_per_class"] = per_class_count.copy()
                
                # –û–±–Ω–æ–≤–ª—è–µ–º session_state –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
                try:
                    st.session_state.camera_last = {
                        "count": cnt, 
                        "ms": float(dt_ms),
                        "per_class": per_class_count.copy()
                    }
                except:
                    pass  # –ï—Å–ª–∏ session_state –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ –ø–æ—Ç–æ–∫–µ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                
                # –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –æ–±—â–∏–π —Å–ª–æ–≤–∞—Ä—å
                if auto_save_enabled:
                    time_since_last_save = current_time - camera_shared_state["last_save"]
                    if time_since_last_save >= auto_save_interval:
                        per_class_snapshot = per_class_count.copy()
                        if not per_class_snapshot and cnt > 0:
                            per_class_snapshot = {"cup": cnt}
                        
                        try:
                            append_history(
                                HistoryRecord(
                                    ts_iso=utc_now_iso(),
                                    kind="camera",
                                    input_name=f"webcam_auto_{camera_shared_state['save_count']}",
                                    model_name=model_path,
                                    target_classes=classes,
                                    conf=float(conf),
                                    iou=float(iou),
                                    total_count=cnt,
                                    per_class_count=per_class_snapshot,
                                    inference_ms=float(dt_ms),
                                ),
                                HISTORY_PATH,
                            )
                            camera_shared_state["last_save"] = current_time
                            camera_shared_state["save_count"] += 1
                            
                            # –û–±–Ω–æ–≤–ª—è–µ–º session_state –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
                            try:
                                st.session_state.camera_last_save = current_time
                                st.session_state.camera_save_count = camera_shared_state["save_count"]
                            except:
                                pass
                        except Exception as e:
                            # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É, –Ω–æ –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
                            print(f"–û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
            
            return av.VideoFrame.from_ndarray(plotted, format="bgr24")

    ctx = webrtc_streamer(
        key="camera",
        video_transformer_factory=YoloVideoTransformer,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
    )

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ)
    with stats_lock:
        current_count = camera_shared_state["last_count"]
        current_ms = camera_shared_state["last_ms"]
        current_per_class = camera_shared_state["last_per_class"].copy()
        # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º —Å—á–µ—Ç—á–∏–∫ –∏–∑ –æ–±—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        if "camera_save_count" in st.session_state:
            st.session_state.camera_save_count = camera_shared_state["save_count"]
        else:
            st.session_state.camera_save_count = camera_shared_state["save_count"]
    
    c1, c2, c3 = st.columns(3)
    c1.metric("–¢–µ–∫—É—â–∏–π –ø–æ–¥—Å—á—ë—Ç", current_count)
    c2.metric("–ò–Ω—Ñ–µ—Ä–µ–Ω—Å –Ω–∞ –∫–∞–¥—Ä (ms)", f"{current_ms:.1f}")
    c3.metric("–ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–π", camera_shared_state["save_count"])
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–ª–∞—Å—Å–∞–º
    if current_per_class:
        st.write("**–ü–æ–¥—Å—á—ë—Ç –ø–æ –∫–ª–∞—Å—Å–∞–º:**")
        st.json(current_per_class)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    if auto_save_enabled and ctx.state.playing:
        time_since_last = time.time() - camera_shared_state["last_save"]
        remaining = max(0, auto_save_interval - time_since_last)
        st.info(f"‚è±Ô∏è –°–ª–µ–¥—É—é—â–µ–µ –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ {remaining:.1f} —Å–µ–∫ (–∏–Ω—Ç–µ—Ä–≤–∞–ª: {auto_save_interval} —Å–µ–∫)")

    if ctx.state.playing and st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–Ω–∏–º–æ–∫ –≤ –∏—Å—Ç–æ—Ä–∏—é –≤—Ä—É—á–Ω—É—é"):
        with stats_lock:
            manual_count = camera_shared_state["last_count"]
            manual_ms = camera_shared_state["last_ms"]
            manual_per_class = camera_shared_state["last_per_class"].copy()
        
        per_class_snapshot = manual_per_class.copy()
        if not per_class_snapshot and manual_count > 0:
            per_class_snapshot = {"cup": manual_count}
        
        append_history(
            HistoryRecord(
                ts_iso=utc_now_iso(),
                kind="camera",
                input_name="webcam_manual",
                model_name=model_path,
                target_classes=classes,
                conf=float(conf),
                iou=float(iou),
                total_count=manual_count,
                per_class_count=per_class_snapshot,
                inference_ms=manual_ms,
            ),
            HISTORY_PATH,
        )
        camera_shared_state["last_save"] = time.time()
        st.success("–°–Ω–∏–º–æ–∫ –¥–æ–±–∞–≤–ª–µ–Ω –≤ –∏—Å—Ç–æ—Ä–∏—é –≤—Ä—É—á–Ω—É—é.")


with tabs[3]:
    rows = read_history(HISTORY_PATH)
    
    # –î–∞—à–±–æ—Ä–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    st.subheader("üìä –î–∞—à–±–æ—Ä–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")
    
    if rows:
        df = pd.DataFrame(rows)
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤", len(df))
        with col2:
            total_objects = df["total_count"].fillna(0).sum()
            st.metric("–í—Å–µ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤", int(total_objects))
        with col3:
            avg_time = df["inference_ms"].fillna(0).mean()
            st.metric("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è (ms)", f"{avg_time:.1f}")
        with col4:
            if "ts_iso" in df.columns:
                df["ts_iso"] = pd.to_datetime(df["ts_iso"], errors="coerce")
                unique_dates = df["ts_iso"].dt.date.nunique()
                st.metric("–î–Ω–µ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏", unique_dates)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º
        st.subheader("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –∑–∞–ø—Ä–æ—Å–æ–≤")
        if "kind" in df.columns:
            kind_counts = df["kind"].value_counts()
            col1, col2 = st.columns(2)
            with col1:
                st.bar_chart(kind_counts)
            with col2:
                st.write("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:**")
                for kind, count in kind_counts.items():
                    st.write(f"- {kind}: {count}")
        
        # –í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞ –ø–æ —á–∞—Å–∞–º
        st.subheader("‚è∞ –í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞ –ø–æ —á–∞—Å–∞–º")
        if "ts_iso" in df.columns and "total_count" in df.columns:
            df["datetime"] = pd.to_datetime(df["ts_iso"], errors="coerce")
            df["hour"] = df["datetime"].dt.hour
            hourly_stats = df.groupby("hour").agg({
                "total_count": "sum",
                "ts_iso": "count"
            }).rename(columns={"ts_iso": "requests"})
            st.line_chart(hourly_stats)
            
            # –ö—Ä—É–≥–æ–≤–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ —á–∞—Å–∞–º
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ —á–∞—Å–∞–º")
                hour_counts = df["hour"].value_counts().sort_index()
                st.bar_chart(hour_counts)
            with col2:
                st.subheader("ü•ß –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ —á–∞—Å–∞–º")
                hour_objects = df.groupby("hour")["total_count"].sum()
                st.area_chart(hour_objects)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤–∏–¥–µ–æ (–¥–∏–Ω–∞–º–∏–∫–∞ –ø–æ –∫–∞–¥—Ä–∞–º)
        st.subheader("üé¨ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤–∏–¥–µ–æ")
        video_rows = [r for r in rows if r.get("kind") == "video"]
        if video_rows:
            st.write(f"–ù–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ –∑–∞–ø–∏—Å–µ–π: **{len(video_rows)}**")
            video_df = pd.DataFrame(video_rows)
            if "total_count" in video_df.columns and "max_per_frame" in video_df.columns:
                col1, col2 = st.columns(2)
                with col1:
                    st.write("**–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞ –∫–∞–¥—Ä:**")
                    st.bar_chart(video_df.set_index("input_name")["total_count"])
                with col2:
                    st.write("**–ú–∞–∫—Å–∏–º—É–º –Ω–∞ –∫–∞–¥—Ä:**")
                    st.bar_chart(video_df.set_index("input_name")["max_per_frame"])
                
                # –¢–æ—á–µ—á–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞: —Å—Ä–µ–¥–Ω–µ–µ vs –º–∞–∫—Å–∏–º—É–º
                st.write("**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –∏ –º–∞–∫—Å–∏–º—É–º–∞:**")
                scatter_data = pd.DataFrame({
                    "–°—Ä–µ–¥–Ω–µ–µ": video_df["total_count"],
                    "–ú–∞–∫—Å–∏–º—É–º": video_df["max_per_frame"]
                })
                st.scatter_chart(scatter_data)
            
            # –î–∏–Ω–∞–º–∏–∫–∞ –ø–æ –∫–∞–¥—Ä–∞–º –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ
            st.subheader("üìπ –î–∏–Ω–∞–º–∏–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç–∞–∫–∞–Ω–æ–≤ –ø–æ –∫–∞–¥—Ä–∞–º")
            frames_index_path = DATA_DIR / "video_frames_index.jsonl"
            if frames_index_path.exists():
                try:
                    import json
                    frames_index = []
                    with frames_index_path.open("r", encoding="utf-8") as f:
                        for line in f:
                            if line.strip():
                                frames_index.append(json.loads(line))
                    
                    if frames_index:
                        video_names = [entry["video_name"] for entry in frames_index]
                        selected_video = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –≤–∏–¥–µ–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞–¥—Ä–æ–≤:", video_names)
                        
                        if selected_video:
                            selected_entry = next((e for e in frames_index if e["video_name"] == selected_video), None)
                            if selected_entry:
                                frames_data_path = Path(selected_entry["frames_data_path"])
                                if frames_data_path.exists():
                                    with frames_data_path.open("r", encoding="utf-8") as f:
                                        frames_data = json.load(f)
                                    
                                    frame_counts = frames_data.get("frame_counts", [])
                                    if frame_counts:
                                        # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
                                        frames_df = pd.DataFrame({
                                            "–ö–∞–¥—Ä": range(len(frame_counts)),
                                            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞–∫–∞–Ω–æ–≤": frame_counts
                                        })
                                        
                                        st.write(f"**–í–∏–¥–µ–æ: {selected_video}**")
                                        st.write(f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤: {len(frame_counts)}")
                                        st.write(f"FPS: {frames_data.get('fps', 'N/A')}")
                                        
                                        # –õ–∏–Ω–µ–π–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ –¥–∏–Ω–∞–º–∏–∫–∏
                                        st.line_chart(frames_df.set_index("–ö–∞–¥—Ä")["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞–∫–∞–Ω–æ–≤"])
                                        
                                        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                                        col1, col2, col3 = st.columns(3)
                                        with col1:
                                            st.metric("–°—Ä–µ–¥–Ω–µ–µ –Ω–∞ –∫–∞–¥—Ä", f"{pd.Series(frame_counts).mean():.2f}")
                                        with col2:
                                            st.metric("–ú–∞–∫—Å–∏–º—É–º –Ω–∞ –∫–∞–¥—Ä", max(frame_counts))
                                        with col3:
                                            st.metric("–ú–∏–Ω–∏–º—É–º –Ω–∞ –∫–∞–¥—Ä", min(frame_counts))
                                else:
                                    st.warning(f"–§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–∞–¥—Ä–∞–º –Ω–µ –Ω–∞–π–¥–µ–Ω: {frames_data_path}")
                            else:
                                st.warning("–î–∞–Ω–Ω—ã–µ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –≤–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    else:
                        st.info("–ù–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–∞–¥—Ä–∞–º –≤–∏–¥–µ–æ")
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–∞–¥—Ä–∞–º: {e}")
            else:
                st.info("–î–∞–Ω–Ω—ã–µ –ø–æ –∫–∞–¥—Ä–∞–º –≤–∏–¥–µ–æ –±—É–¥—É—Ç –¥–æ—Å—Ç—É–ø–Ω—ã –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ")
        else:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤–∏–¥–µ–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        # –¢–æ–ø –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –æ–±—ä–µ–∫—Ç–æ–≤
        st.subheader("üèÜ –¢–æ–ø –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –æ–±—ä–µ–∫—Ç–æ–≤")
        if "total_count" in df.columns and "input_name" in df.columns:
            top_requests = df.nlargest(10, "total_count")[["input_name", "total_count", "ts_iso", "kind"]]
            st.dataframe(top_requests, use_container_width=True, hide_index=True)
            
            # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—ä–µ–∫—Ç–æ–≤
            st.subheader("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—ä–µ–∫—Ç–æ–≤")
            try:
                import matplotlib.pyplot as plt
                fig, ax = plt.subplots()
                counts = df["total_count"].dropna()
                ax.hist(counts, bins=min(20, len(counts.unique())), edgecolor='black')
                ax.set_xlabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤")
                ax.set_ylabel("–ß–∞—Å—Ç–æ—Ç–∞")
                ax.set_title("–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—ä–µ–∫—Ç–æ–≤")
                st.pyplot(fig)
                plt.close(fig)
            except ImportError:
                # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º bar_chart —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π
                counts = df["total_count"].dropna()
                if len(counts) > 0:
                    bins = pd.cut(counts, bins=min(10, len(counts.unique())), precision=0)
                    hist_data = bins.value_counts().sort_index()
                    hist_df = pd.DataFrame({
                        "–ò–Ω—Ç–µ—Ä–≤–∞–ª": [str(x) for x in hist_data.index],
                        "–ß–∞—Å—Ç–æ—Ç–∞": hist_data.values
                    })
                    st.bar_chart(hist_df.set_index("–ò–Ω—Ç–µ—Ä–≤–∞–ª"))
    
    st.divider()
    
    # –ò—Å—Ç–æ—Ä–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
    st.subheader("üìã –ò—Å—Ç–æ—Ä–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤")
    st.write(f"–§–∞–π–ª: `{HISTORY_PATH.as_posix()}`. –ó–∞–ø–∏—Å–µ–π: **{len(rows)}**")
    st.dataframe(rows, use_container_width=True, height=320)

    c1, c2, c3 = st.columns(3)
    with c1:
        excel = make_excel_bytes(rows)
        st.download_button("–°–∫–∞—á–∞—Ç—å Excel", data=excel, file_name="history.xlsx")
    with c2:
        pdf = make_pdf_bytes(rows)
        st.download_button("–°–∫–∞—á–∞—Ç—å PDF", data=pdf, file_name="report.pdf")
    with c3:
        if st.button("–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é", type="secondary", disabled=len(rows) == 0):
            clear_history(HISTORY_PATH)
            st.session_state.camera_save_count = 0
            st.rerun()

