# app.py (–æ–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
from __future__ import annotations

import json
import tempfile
from pathlib import Path
from typing import Dict, List

import numpy as np
import pandas as pd
import streamlit as st
from PIL import Image

from src.analytics import AnalyticsEngine
from src.camera import CameraProcessor, get_camera_processor, reset_camera_processor
from src.history_manager import HistoryManager
from src.infer import detect_and_count_on_image, detect_and_count_on_video
from src.reports import make_excel_bytes, make_pdf_bytes

import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

from datetime import datetime, timezone

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
APP_TITLE = "–ü—Ä–∞–∫—Ç–∏–∫–∞ CV: –ø–æ–¥—Å—á—ë—Ç —Å—Ç–∞–∫–∞–Ω–æ–≤/–∫—Ä—É–∂–µ–∫ (YOLOv8)"
DATA_DIR = Path("data")
HISTORY_PATH = DATA_DIR / "history.jsonl"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤
history_manager = HistoryManager(HISTORY_PATH)
analytics_engine = AnalyticsEngine(history_manager)


def _parse_target_classes(text: str) -> List[str]:
    """–ü–∞—Ä—Å–∏—Ç —Ü–µ–ª–µ–≤—ã–µ –∫–ª–∞—Å—Å—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    raw = [t.strip() for t in text.replace(";", ",").split(",")]
    return [t for t in raw if t]


def _save_uploaded_to_temp(uploaded) -> str:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª"""
    suffix = Path(uploaded.name).suffix or ""
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as f:
        f.write(uploaded.getbuffer())
        return f.name


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title=APP_TITLE, layout="wide")
st.title(APP_TITLE)

# –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å
with st.sidebar:
    st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏")
    model_path = st.text_input("–ú–æ–¥–µ–ª—å (–≤–µ—Å–∞ Ultralytics)", value="yolov8n.pt")
    conf = st.slider("Confidence", 0.05, 0.95, 0.35, 0.05)
    iou = st.slider("IoU", 0.05, 0.95, 0.45, 0.05)

    st.subheader("–í–∏–¥–µ–æ")
    sample_every = st.number_input("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∫–∞–∂–¥—ã–π N‚Äë–π –∫–∞–¥—Ä", min_value=1, max_value=30, value=1, step=1)

    st.subheader("–ö–∞–º–µ—Ä–∞")
    auto_save_enabled = st.checkbox("–ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ", value=True)
    auto_save_interval = st.number_input("–ò–Ω—Ç–µ—Ä–≤–∞–ª –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (—Å–µ–∫)",
                                         min_value=5, max_value=300, value=15, step=5,
                                         disabled=not auto_save_enabled)

# –í–∫–ª–∞–¥–∫–∏
tabs = st.tabs(["–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "–í–∏–¥–µ–æ", "–ö–∞–º–µ—Ä–∞", "–ò—Å—Ç–æ—Ä–∏—è –∏ –æ—Ç—á—ë—Ç—ã"])

with tabs[0]:
    st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–Ω–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –Ω–∞–∂–º–∏—Ç–µ **–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É**.")

    up_list = st.file_uploader(
        "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (jpg/png/webp)",
        type=["jpg", "jpeg", "png", "webp"],
        accept_multiple_files=True
    )

    run = st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", type="primary", disabled=not up_list)

    if up_list:
        st.write(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: **{len(up_list)}**")
        cols = st.columns(min(3, len(up_list)))
        for idx, up in enumerate(up_list):
            with cols[idx % len(cols)]:
                img = Image.open(up).convert("RGB")
                st.image(img, caption=up.name, use_container_width=True)

    if run and up_list:
        classes = ["cup"]
        progress_bar = st.progress(0)
        status_text = st.empty()

        for idx, up in enumerate(up_list):
            status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {idx + 1}/{len(up_list)}: {up.name}")
            progress_bar.progress((idx + 1) / len(up_list))

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image_rgb = np.array(Image.open(up).convert("RGB"))
            annotated_rgb, summary = detect_and_count_on_image(
                image_rgb,
                model_path=model_path,
                target_classes=classes,
                conf=float(conf),
                iou=float(iou),
            )

            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            st.subheader(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {up.name}")
            col1, col2 = st.columns([2, 1])
            with col1:
                st.image(annotated_rgb, caption="–ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_container_width=True)
            with col2:
                st.metric("–í—Å–µ–≥–æ –æ–±—ä–µ–∫—Ç–æ–≤", summary.total_count)
                st.metric("–í—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ (ms)", f"{summary.inference_ms:.1f}")
                st.metric("–ö–ª–∞—Å—Å—ã", ", ".join(summary.selected_class_names))
                st.json(summary.per_class_count)

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
            history_manager.add_image_record(
                input_name=up.name,
                model_name=summary.model_name,
                total_count=summary.total_count,
                per_class_count=summary.per_class_count,
                inference_ms=summary.inference_ms,
                target_classes=classes,
                conf=summary.conf_threshold,
                iou=summary.iou_threshold,
                image_width=summary.image_width,
                image_height=summary.image_height,
            )

        progress_bar.empty()
        status_text.empty()
        st.success(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(up_list)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ó–∞–ø–∏—Å–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ –∏—Å—Ç–æ—Ä–∏—é.")

with tabs[1]:
    st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–Ω–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∏–¥–µ–æ –∏ –Ω–∞–∂–º–∏—Ç–µ **–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É**.")

    if "video_results" not in st.session_state:
        st.session_state.video_results = []

    upv_list = st.file_uploader(
        "–í–∏–¥–µ–æ (mp4/avi/mov)",
        type=["mp4", "avi", "mov"],
        accept_multiple_files=True,
        key="video_uploader"
    )

    if st.session_state.video_results:
        col1, col2 = st.columns([1, 4])
        with col1:
            if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã", type="secondary"):
                st.session_state.video_results = []
                st.rerun()

    runv = st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∏–¥–µ–æ", type="primary", disabled=not upv_list)

    if upv_list:
        st.write(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤–∏–¥–µ–æ: **{len(upv_list)}**")
        for upv in upv_list:
            st.text(f"üìπ {upv.name} ({upv.size / 1024 / 1024:.2f} MB)")

    # –ü–æ–∫–∞–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if st.session_state.video_results:
        st.divider()
        st.subheader("üìπ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ")

        for result_idx, result in enumerate(st.session_state.video_results):
            st.subheader(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result['input_name']}")
            st.write(
                f"–ü–æ–¥—Å—á—ë—Ç: **{result['total_count']}** (—Å—Ä–µ–¥–Ω–µ–µ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∫–∞–¥—Ä), "
                f"–º–∞–∫—Å–∏–º—É–º –Ω–∞ –∫–∞–¥—Ä: **{result['max_per_frame']}**"
            )
            st.write(f"–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (ms): **{result['inference_ms']:.1f}**")

            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–∏–¥–µ–æ
            video_file = Path(result['out_path'])
            if video_file.exists() and video_file.stat().st_size > 0:
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
                    file_size_mb = video_file.stat().st_size / (1024 * 1024)

                    if file_size_mb > 50:  # –ï—Å–ª–∏ —Ñ–∞–π–ª –±–æ–ª—å—à–µ 50 MB
                        st.warning(f"–í–∏–¥–µ–æ —Ñ–∞–π–ª –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π ({file_size_mb:.1f} MB). –î–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–∫–∞—á–∞–π—Ç–µ –µ–≥–æ.")

                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–π –∫–∞–¥—Ä –∫–∞–∫ –ø—Ä–µ–≤—å—é
                        try:
                            import cv2

                            cap = cv2.VideoCapture(str(video_file))
                            ret, frame = cap.read()
                            if ret:
                                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º BGR –≤ RGB
                                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                                st.image(frame_rgb, caption="–ü–µ—Ä–≤—ã–π –∫–∞–¥—Ä –≤–∏–¥–µ–æ", use_container_width=True)
                            cap.release()
                        except:
                            pass
                    else:
                        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≤–∏–¥–µ–æ –Ω–∞–ø—Ä—è–º—É—é
                        with open(video_file, "rb") as f:
                            video_bytes = f.read()

                        st.video(video_bytes)

                    # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                    st.download_button(
                        label=f"üíæ –°–∫–∞—á–∞—Ç—å –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ ({file_size_mb:.1f} MB)",
                        data=video_bytes if file_size_mb <= 50 else open(video_file, "rb").read(),
                        file_name=video_file.name,
                        mime="video/mp4",
                        key=f"download_video_{result_idx}"
                    )

                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –≤–∏–¥–µ–æ: {str(e)}")
                    st.code(
                        f"–ü—É—Ç—å: {video_file}\n–†–∞–∑–º–µ—Ä: {video_file.stat().st_size if video_file.exists() else '—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'} –±–∞–π—Ç")

                    # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    try:
                        # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å st.video —Å –ø—É—Ç–µ–º
                        st.video(str(video_file))
                    except Exception as e2:
                        st.error(f"–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ —Ç–∞–∫–∂–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {str(e2)}")
            else:
                st.error(f"–í–∏–¥–µ–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –ø—É—Å—Ç: {video_file}")
                if video_file.exists():
                    st.info(f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {video_file.stat().st_size} –±–∞–π—Ç")
            st.divider()

    if runv and upv_list:
        classes = ["cup"]
        progress_bar = st.progress(0)
        status_text = st.empty()

        for idx, upv in enumerate(upv_list):
            status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ {idx + 1}/{len(upv_list)}: {upv.name}...")
            progress_bar.progress((idx + 1) / len(upv_list))

            tmp_in = _save_uploaded_to_temp(upv)

            # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è –≤–∏–¥–µ–æ
            video_progress = st.progress(0)
            video_status = st.empty()


            def update_video_progress(p: float):
                video_progress.progress(p)
                video_status.text(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤: {p * 100:.1f}%")


            with st.spinner(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {upv.name}..."):
                out_path, summary, frames_data_path, frame_counts = detect_and_count_on_video(
                    tmp_in,
                    model_path=model_path,
                    target_classes=classes,
                    conf=float(conf),
                    iou=float(iou),
                    sample_every_n_frames=int(sample_every),
                    progress_callback=update_video_progress,
                )

            video_progress.empty()
            video_status.empty()

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            result_data = {
                "input_name": upv.name,
                "out_path": out_path,
                "total_count": summary.total_count,
                "max_per_frame": summary.max_per_frame,
                "inference_ms": summary.inference_ms,
                "summary": summary,
                "frames_data_path": frames_data_path,
                "frame_counts": frame_counts
            }
            st.session_state.video_results.append(result_data)

            st.success(f"‚úÖ –í–∏–¥–µ–æ {upv.name} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ!")

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
            history_manager.add_video_record(
                input_name=upv.name,
                model_name=summary.model_name,
                total_count=summary.total_count,
                per_class_count=summary.per_class_count,
                inference_ms=summary.inference_ms,
                output_artifact=str(out_path),
                max_per_frame=summary.max_per_frame,
                target_classes=classes,
                conf=summary.conf_threshold,
                iou=summary.iou_threshold,
                image_width=summary.image_width,
                image_height=summary.image_height,
            )

        if frames_data_path:
            try:
                frames_index_path = DATA_DIR / "video_frames_index.jsonl"
                frames_index_path.parent.mkdir(parents=True, exist_ok=True)
                with frames_index_path.open("a", encoding="utf-8") as f:
                    index_entry = {
                        "video_name": upv.name,
                        "frames_data_path": frames_data_path,
                        "ts_iso": datetime.now(timezone.utc).replace(microsecond=0).isoformat()
                    }
                    f.write(json.dumps(index_entry, ensure_ascii=False) + "\n")
            except Exception as e:
                st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–Ω–¥–µ–∫—Å –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–∞–¥—Ä–∞–º: {e}")

        progress_bar.empty()
        status_text.empty()
        st.rerun()

with tabs[2]:
    st.write("–ù–∞–∂–º–∏—Ç–µ **Start**, —á—Ç–æ–±—ã –æ—Ç–∫—Ä—ã—Ç—å –ø–æ—Ç–æ–∫ —Å –∫–∞–º–µ—Ä—ã. –û–Ω–ª–∞–π–Ω-–ø–æ–¥—Å—á–µ—Ç –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.")

    import time
    import av
    from streamlit_webrtc import VideoTransformerBase, webrtc_streamer

    # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –ø–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∫–∞–º–µ—Ä—ã
    camera_processor = get_camera_processor(
        model_path=model_path,
        target_classes=["cup"],
        conf=float(conf),
        iou=float(iou)
    )


    class OnlineCameraTransformer(VideoTransformerBase):
        """–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –¥–ª—è –æ–Ω–ª–∞–π–Ω-–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–º–µ—Ä—ã"""

        def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
            img = frame.to_ndarray(format="bgr24")

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞
            annotated_frame, count, inference_ms, per_class_count = camera_processor.process_frame(img)

            # –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            if auto_save_enabled:
                current_time = time.time()
                time_since_last = current_time - camera_processor.state.last_save

                if time_since_last >= auto_save_interval:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
                    history_manager.add_camera_record(
                        input_name=f"webcam_auto_{camera_processor.state.save_count}",
                        model_name=model_path,
                        total_count=count,
                        per_class_count=per_class_count,
                        inference_ms=inference_ms,
                        target_classes=["cup"],
                        conf=float(conf),
                        iou=float(iou),
                    )

                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
                    with camera_processor.state.lock:
                        camera_processor.state.last_save = current_time
                        camera_processor.state.save_count += 1

            return av.VideoFrame.from_ndarray(annotated_frame, format="bgr24")


    # –ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–∞ –∫–∞–º–µ—Ä—ã
    ctx = webrtc_streamer(
        key="online_camera",
        video_transformer_factory=OnlineCameraTransformer,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
    )

    # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –¥–ª—è –æ–Ω–ª–∞–π–Ω-–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
    metrics_container = st.container()
    stats_container = st.container()


    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    def update_camera_ui():
        with metrics_container:
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            count, inference_ms, per_class_count, save_count = camera_processor.get_current_stats()

            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            c1, c2, c3, c4 = st.columns(4)
            with c1:
                st.metric("üìä –¢–µ–∫—É—â–∏–π –ø–æ–¥—Å—á–µ—Ç", count, delta=None)
            with c2:
                st.metric("‚ö° –ò–Ω—Ñ–µ—Ä–µ–Ω—Å", f"{inference_ms:.1f} ms")
            with c3:
                st.metric("üíæ –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–π", save_count)
            with c4:
                if auto_save_enabled:
                    time_since_last = time.time() - camera_processor.state.last_save
                    remaining = max(0, auto_save_interval - time_since_last)
                    st.metric("‚è±Ô∏è –°–ª–µ–¥—É—é—â–µ–µ", f"{remaining:.0f} —Å–µ–∫")

        with stats_container:
            # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            if per_class_count:
                st.write("**–î–µ—Ç–∞–ª—å–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∞–º:**")

                # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Å–∏–≤—É—é —Ç–∞–±–ª–∏—Ü—É
                class_data = []
                for class_name, class_count in per_class_count.items():
                    class_data.append({
                        "–ö–ª–∞—Å—Å": class_name,
                        "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ": class_count,
                        "–ü—Ä–æ—Ü–µ–Ω—Ç": f"{(class_count / max(1, count) * 100):.1f}%"
                    })

                if class_data:
                    stats_df = pd.DataFrame(class_data)
                    st.dataframe(stats_df, use_container_width=True, hide_index=True)
            elif count > 0:
                st.info(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å—Ç–∞–∫–∞–Ω–æ–≤/–∫—Ä—É–∂–µ–∫: **{count}**")
            else:
                st.info("üîç –û–∂–∏–¥–∞–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤...")


    # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
    if ctx.state.playing:
        camera_processor.start()
        update_camera_ui()

        # –ö–Ω–æ–ø–∫–∞ —Ä—É—á–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–µ–∫—É—â–∏–π —Å–Ω–∏–º–æ–∫ –≤—Ä—É—á–Ω—É—é", type="secondary"):
            count, inference_ms, per_class_count, _ = camera_processor.get_current_stats()

            history_manager.add_camera_record(
                input_name="webcam_manual",
                model_name=model_path,
                total_count=count,
                per_class_count=per_class_count,
                inference_ms=inference_ms,
                target_classes=["cup"],
                conf=float(conf),
                iou=float(iou),
            )

            st.success("–°–Ω–∏–º–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –∏—Å—Ç–æ—Ä–∏—é!")
            st.rerun()
    else:
        camera_processor.stop()
        st.info("üëÜ –ù–∞–∂–º–∏—Ç–µ 'Start' –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∫–∞–º–µ—Ä—ã")

with tabs[3]:
    rows = history_manager.get_all_records()

    # –î–∞—à–±–æ—Ä–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    st.subheader("üìä –î–∞—à–±–æ—Ä–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")

    if rows:
        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        basic_stats = analytics_engine.get_basic_stats()

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤", basic_stats["total_requests"])
        with col2:
            st.metric("–í—Å–µ–≥–æ –æ–±—ä–µ–∫—Ç–æ–≤", basic_stats["total_objects"])
        with col3:
            st.metric("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è", f"{basic_stats['avg_inference_time']:.1f} ms")
        with col4:
            st.metric("–î–Ω–µ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏", basic_stats["active_days"])

        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º")
            kind_dist = analytics_engine.get_kind_distribution()
            if not kind_dist.empty:
                fig = px.pie(kind_dist, values='count', names='kind',
                             title="–¢–∏–ø—ã –∑–∞–ø—Ä–æ—Å–æ–≤")
                st.plotly_chart(fig, use_container_width=True)

        with col2:
            st.subheader("‚è∞ –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ —á–∞—Å–∞–º")
            hourly_stats = analytics_engine.get_hourly_stats()
            if not hourly_stats.empty:
                fig = px.bar(hourly_stats, x='hour', y='requests',
                             title="–ó–∞–ø—Ä–æ—Å—ã –ø–æ —á–∞—Å–∞–º")
                st.plotly_chart(fig, use_container_width=True)

        # –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –≤–∏–¥–µ–æ
        st.subheader("üé¨ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤–∏–¥–µ–æ")
        video_analytics = analytics_engine.get_video_analytics()

        if video_analytics["video_count"] > 0:
            video_df = video_analytics["data"]

            col1, col2 = st.columns(2)
            with col1:
                st.write("**–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞ –∫–∞–¥—Ä:**")
                fig = px.bar(video_df, x='input_name', y='total_count',
                             title="–°—Ä–µ–¥–Ω–µ–µ –Ω–∞ –∫–∞–¥—Ä")
                st.plotly_chart(fig, use_container_width=True)

            with col2:
                st.write("**–ú–∞–∫—Å–∏–º—É–º –Ω–∞ –∫–∞–¥—Ä:**")
                fig = px.bar(video_df, x='input_name', y='max_per_frame',
                             title="–ú–∞–∫—Å–∏–º—É–º –Ω–∞ –∫–∞–¥—Ä")
                st.plotly_chart(fig, use_container_width=True)

            # –ê–Ω–∞–ª–∏–∑ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ
            st.subheader("üìπ –ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏ –ø–æ –∫–∞–¥—Ä–∞–º")

            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –¥–∞–Ω–Ω—ã–µ –ø–æ –∫–∞–¥—Ä–∞–º
            frames_index_path = DATA_DIR / "video_frames_index.jsonl"
            if frames_index_path.exists():
                try:
                    frames_index = []
                    with frames_index_path.open("r", encoding="utf-8") as f:
                        for line in f:
                            if line.strip():
                                frames_index.append(json.loads(line))

                    if frames_index:
                        video_names = [entry["video_name"] for entry in frames_index]
                        selected_video = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –≤–∏–¥–µ–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:", video_names)

                        if selected_video:
                            selected_entry = next((e for e in frames_index if e["video_name"] == selected_video), None)
                            if selected_entry:
                                frames_data_path = Path(selected_entry["frames_data_path"])
                                frame_analysis = analytics_engine.get_frame_analysis(
                                    selected_video, frames_data_path
                                )

                                if frame_analysis:
                                    st.write(f"**–í–∏–¥–µ–æ: {selected_video}**")

                                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                                    col1, col2, col3, col4 = st.columns(4)
                                    with col1:
                                        st.metric("–í—Å–µ–≥–æ –∫–∞–¥—Ä–æ–≤", frame_analysis["total_frames"])
                                    with col2:
                                        st.metric("–°—Ä–µ–¥–Ω–µ–µ", f"{frame_analysis['frame_stats']['mean']:.2f}")
                                    with col3:
                                        st.metric("–ú–∞–∫—Å–∏–º—É–º", frame_analysis['frame_stats']['max'])
                                    with col4:
                                        st.metric("FPS", frame_analysis['fps'])

                                    # –ì—Ä–∞—Ñ–∏–∫ –¥–∏–Ω–∞–º–∏–∫–∏
                                    fig = go.Figure()
                                    fig.add_trace(go.Scatter(
                                        y=frame_analysis["frame_counts"],
                                        mode='lines',
                                        name='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞–∫–∞–Ω–æ–≤',
                                        line=dict(color='blue', width=2)
                                    ))
                                    fig.update_layout(
                                        title=f"–î–∏–Ω–∞–º–∏–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç–∞–∫–∞–Ω–æ–≤: {selected_video}",
                                        xaxis_title="–ù–æ–º–µ—Ä –∫–∞–¥—Ä–∞",
                                        yaxis_title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞–∫–∞–Ω–æ–≤",
                                        height=400
                                    )
                                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∫–∞–¥—Ä–æ–≤: {e}")

    st.divider()

    # –ò—Å—Ç–æ—Ä–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
    st.subheader("üìã –ò—Å—Ç–æ—Ä–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤")
    st.write(f"–ó–∞–ø–∏—Å–µ–π –≤ –∏—Å—Ç–æ—Ä–∏–∏: **{len(rows)}**")

    if rows:
        df = pd.DataFrame(rows)
        st.dataframe(df, use_container_width=True, height=400)
    else:
        st.info("–ò—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞")

    # –≠–∫—Å–ø–æ—Ä—Ç
    st.subheader("üì§ –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö")
    col1, col2, col3 = st.columns(3)

    with col1:
        if rows:
            excel_data = make_excel_bytes(rows)
            st.download_button(
                "üìä –°–∫–∞—á–∞—Ç—å Excel",
                data=excel_data,
                file_name="history.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        else:
            st.button("üìä –°–∫–∞—á–∞—Ç—å Excel", disabled=True)

    with col2:
        if rows:
            pdf_data = make_pdf_bytes(rows)
            st.download_button(
                "üìÑ –°–∫–∞—á–∞—Ç—å PDF",
                data=pdf_data,
                file_name="report.pdf",
                mime="application/pdf"
            )
        else:
            st.button("üìÑ –°–∫–∞—á–∞—Ç—å PDF", disabled=True)

    with col3:
        if rows and st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é", type="secondary"):
            history_manager.clear_history()
            reset_camera_processor()
            st.success("–ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞!")
            st.rerun()